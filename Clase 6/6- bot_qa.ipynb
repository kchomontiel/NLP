{"cells":[{"cell_type":"markdown","metadata":{"id":"pfa39F4lsLf3"},"source":["<img src=\"https://github.com/hernancontigiani/ceia_memorias_especializacion/raw/master/Figures/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n","\n","\n","# Procesamiento de lenguaje natural\n","## LSTM Bot QA"]},{"cell_type":"markdown","metadata":{"id":"ZqO0PRcFsPTe"},"source":["### Datos\n","El objecto es utilizar datos disponibles del challenge ConvAI2 (Conversational Intelligence Challenge 2) de conversaciones en inglés. Se construirá un BOT para responder a preguntas del usuario (QA).\\\n","[LINK](http://convai.io/data/)"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"bDFC0I3j9oFD"},"outputs":[],"source":["!pip install --upgrade --no-cache-dir gdown --quiet"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"cq3YXak9sGHd"},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-12-12 15:33:12.534566: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"]}],"source":["import re\n","\n","import numpy as np\n","import pandas as pd\n","\n","import tensorflow as tf\n","from keras.preprocessing.text import one_hot\n","from tensorflow.keras.utils import pad_sequences\n","from keras.models import Sequential\n","from keras.layers import Activation, Dropout, Dense\n","from keras.layers import Flatten, LSTM, SimpleRNN\n","from keras.models import Model\n","from tensorflow.keras.layers import Embedding\n","from sklearn.model_selection import train_test_split\n","from keras.preprocessing.text import Tokenizer\n","from keras.layers import Input"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"RHNkUaPp6aYq"},"outputs":[{"name":"stdout","output_type":"stream","text":["El dataset ya se encuentra descargado\n"]}],"source":["# Descargar la carpeta de dataset\n","import os\n","import gdown\n","if os.access('data_volunteers.json', os.F_OK) is False:\n","    url = 'https://drive.google.com/uc?id=1awUxYwImF84MIT5-jCaYAPe2QwSgS1hN&export=download'\n","    output = 'data_volunteers.json'\n","    gdown.download(url, output, quiet=False)\n","else:\n","    print(\"El dataset ya se encuentra descargado\")"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"WZy1-wgG-Rp7"},"outputs":[],"source":["# dataset_file\n","import json\n","\n","text_file = \"data_volunteers.json\"\n","with open(text_file) as f:\n","    data = json.load(f) # la variable data será un diccionario\n","\n"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"ue5qd54S-eew"},"outputs":[{"data":{"text/plain":["dict_keys(['dialog', 'start_time', 'end_time', 'bot_profile', 'user_profile', 'eval_score', 'profile_match', 'participant1_id', 'participant2_id'])"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["# Observar los campos disponibles en cada linea del dataset\n","data[0].keys()"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"jHBRAXPl-3dz"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cantidad de rows utilizadas: 6033\n"]}],"source":["chat_in = []\n","chat_out = []\n","\n","input_sentences = []\n","output_sentences = []\n","output_sentences_inputs = []\n","max_len = 30\n","\n","def clean_text(txt):\n","    txt = txt.lower()    \n","    txt.replace(\"\\'d\", \" had\")\n","    txt.replace(\"\\'s\", \" is\")\n","    txt.replace(\"\\'m\", \" am\")\n","    txt.replace(\"don't\", \"do not\")\n","    txt = re.sub(r'\\W+', ' ', txt)\n","    \n","    return txt\n","\n","for line in data:\n","    for i in range(len(line['dialog'])-1):\n","        # vamos separando el texto en \"preguntas\" (chat_in)\n","        # y \"respuestas\" (chat_out)\n","        chat_in = clean_text(line['dialog'][i]['text'])\n","        chat_out = clean_text(line['dialog'][i+1]['text'])\n","\n","        if len(chat_in) >= max_len or len(chat_out) >= max_len:\n","            continue\n","\n","        input_sentence, output = chat_in, chat_out\n","        \n","        # output sentence (decoder_output) tiene <eos>\n","        output_sentence = output + ' <eos>'\n","        # output sentence input (decoder_input) tiene <sos>\n","        output_sentence_input = '<sos> ' + output\n","\n","        input_sentences.append(input_sentence)\n","        output_sentences.append(output_sentence)\n","        output_sentences_inputs.append(output_sentence_input)\n","\n","print(\"Cantidad de rows utilizadas:\", len(input_sentences))"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"07L1qj8pC_l6"},"outputs":[{"data":{"text/plain":["('hi how are you ', 'not bad and you  <eos>', '<sos> not bad and you ')"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["input_sentences[1], output_sentences[1], output_sentences_inputs[1]"]},{"cell_type":"markdown","metadata":{"id":"8P-ynUNP5xp6"},"source":["### 2 - Preprocesamiento\n","Realizar el preprocesamiento necesario para obtener:\n","- word2idx_inputs, max_input_len\n","- word2idx_outputs, max_out_len, num_words_output\n","- encoder_input_sequences, decoder_output_sequences, decoder_targets"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["MAX_VOCAB_SIZE = 8000"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Palabras en el vocabulario: 1799\n","Sentencia de entrada más larga: 9\n"]}],"source":["from keras.preprocessing.text import Tokenizer\n","\n","# tokenizador de inglés\n","input_tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE)\n","input_tokenizer.fit_on_texts(input_sentences)\n","input_integer_seq = input_tokenizer.texts_to_sequences(input_sentences)\n","\n","word2idx_inputs = input_tokenizer.word_index\n","print(\"Palabras en el vocabulario:\", len(word2idx_inputs))\n","\n","max_input_len = max(len(sen) for sen in input_integer_seq)\n","print(\"Sentencia de entrada más larga:\", max_input_len)"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Palabras en el vocabulario: 1806\n","Sentencia de salida más larga: 10\n"]}],"source":["# tokenizador de español\n","# A los filtros de símbolos del Tokenizer agregamos el \"¿\",\n","# sacamos los \"<>\" para que no afectar nuestros tokens\n","output_tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE, filters='!\"#$%&()*+,-./:;=¿?@[\\\\]^_`{|}~\\t\\n')\n","output_tokenizer.fit_on_texts([\"<sos>\", \"<eos>\"] + output_sentences)\n","output_integer_seq = output_tokenizer.texts_to_sequences(output_sentences)\n","output_input_integer_seq = output_tokenizer.texts_to_sequences(output_sentences_inputs)\n","\n","word2idx_outputs = output_tokenizer.word_index\n","print(\"Palabras en el vocabulario:\", len(word2idx_outputs))\n","\n","num_words_output = min(len(word2idx_outputs) + 1, MAX_VOCAB_SIZE) \n","# Se suma 1 para incluir el token de palabra desconocida\n","\n","max_out_len = max(len(sen) for sen in output_integer_seq)\n","print(\"Sentencia de salida más larga:\", max_out_len)"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"data":{"text/plain":["(6033, 10, 1807)"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["from keras.utils import to_categorical\n","decoder_output_sequences = pad_sequences(output_integer_seq, maxlen=max_out_len, padding='post')\n","decoder_targets = to_categorical(decoder_output_sequences, num_classes=num_words_output)\n","decoder_targets.shape"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Cantidad de rows del dataset: 6033\n","encoder_input_sequences shape: (6033, 9)\n","decoder_input_sequences shape: (6033, 10)\n"]}],"source":["print(\"Cantidad de rows del dataset:\", len(input_integer_seq))\n","\n","encoder_input_sequences = pad_sequences(input_integer_seq, maxlen=max_input_len)\n","print(\"encoder_input_sequences shape:\", encoder_input_sequences.shape)\n","\n","decoder_input_sequences = pad_sequences(output_input_integer_seq, maxlen=max_out_len, padding='post')\n","print(\"decoder_input_sequences shape:\", decoder_input_sequences.shape)"]},{"cell_type":"markdown","metadata":{"id":"_CJIsLBbj6rg"},"source":["### 3 - Preparar los embeddings\n","Utilizar los embeddings de Glove o FastText para transformar los tokens de entrada en vectores"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n","  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n","100 2746M  100 2746M    0     0  36.3M      0  0:01:15  0:01:15 --:--:-- 37.9M\n"]}],"source":["# Descargar los embeddings desde un gogle drive (es la forma más rápida)\n","# NOTA: No hay garantía de que estos links perduren, en caso de que no estén\n","# disponibles descargar de la página oficial como se explica en el siguiente bloque\n","!curl -L -o 'fasttext.pkl' 'https://drive.google.com/u/0/uc?id=1Qi1r-u5lsEsNqRSxLrpNOqQ3B_ufltCa&export=download&confirm=t'"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[],"source":["import logging\n","import os\n","from pathlib import Path\n","from io import StringIO\n","import pickle\n","\n","class WordsEmbeddings(object):\n","    logger = logging.getLogger(__name__)\n","\n","    def __init__(self):\n","        # load the embeddings\n","        words_embedding_pkl = Path(self.PKL_PATH)\n","        if not words_embedding_pkl.is_file():\n","            words_embedding_txt = Path(self.WORD_TO_VEC_MODEL_TXT_PATH)\n","            assert words_embedding_txt.is_file(), 'Words embedding not available'\n","            embeddings = self.convert_model_to_pickle()\n","        else:\n","            embeddings = self.load_model_from_pickle()\n","        self.embeddings = embeddings\n","        # build the vocabulary hashmap\n","        index = np.arange(self.embeddings.shape[0])\n","        # Dicctionarios para traducir de embedding a IDX de la palabra\n","        self.word2idx = dict(zip(self.embeddings['word'], index))\n","        self.idx2word = dict(zip(index, self.embeddings['word']))\n","\n","    def get_words_embeddings(self, words):\n","        words_idxs = self.words2idxs(words)\n","        return self.embeddings[words_idxs]['embedding']\n","\n","    def words2idxs(self, words):\n","        return np.array([self.word2idx.get(word, -1) for word in words])\n","\n","    def idxs2words(self, idxs):\n","        return np.array([self.idx2word.get(idx, '-1') for idx in idxs])\n","\n","    def load_model_from_pickle(self):\n","        self.logger.debug(\n","            'loading words embeddings from pickle {}'.format(\n","                self.PKL_PATH\n","            )\n","        )\n","        max_bytes = 2**28 - 1 # 256MB\n","        bytes_in = bytearray(0)\n","        input_size = os.path.getsize(self.PKL_PATH)\n","        with open(self.PKL_PATH, 'rb') as f_in:\n","            for _ in range(0, input_size, max_bytes):\n","                bytes_in += f_in.read(max_bytes)\n","        embeddings = pickle.loads(bytes_in)\n","        self.logger.debug('words embeddings loaded')\n","        return embeddings\n","\n","    def convert_model_to_pickle(self):\n","        # create a numpy strctured array:\n","        # word     embedding\n","        # U50      np.float32[]\n","        # word_1   a, b, c\n","        # word_2   d, e, f\n","        # ...\n","        # word_n   g, h, i\n","        self.logger.debug(\n","            'converting and loading words embeddings from text file {}'.format(\n","                self.WORD_TO_VEC_MODEL_TXT_PATH\n","            )\n","        )\n","        structure = [('word', np.dtype('U' + str(self.WORD_MAX_SIZE))),\n","                     ('embedding', np.float32, (self.N_FEATURES,))]\n","        structure = np.dtype(structure)\n","        # load numpy array from disk using a generator\n","        with open(self.WORD_TO_VEC_MODEL_TXT_PATH, encoding=\"utf8\") as words_embeddings_txt:\n","            embeddings_gen = (\n","                (line.split()[0], line.split()[1:]) for line in words_embeddings_txt\n","                if len(line.split()[1:]) == self.N_FEATURES\n","            )\n","            embeddings = np.fromiter(embeddings_gen, structure)\n","        # add a null embedding\n","        null_embedding = np.array(\n","            [('null_embedding', np.zeros((self.N_FEATURES,), dtype=np.float32))],\n","            dtype=structure\n","        )\n","        embeddings = np.concatenate([embeddings, null_embedding])\n","        # dump numpy array to disk using pickle\n","        max_bytes = 2**28 - 1 # # 256MB\n","        bytes_out = pickle.dumps(embeddings, protocol=pickle.HIGHEST_PROTOCOL)\n","        with open(self.PKL_PATH, 'wb') as f_out:\n","            for idx in range(0, len(bytes_out), max_bytes):\n","                f_out.write(bytes_out[idx:idx+max_bytes])\n","        self.logger.debug('words embeddings loaded')\n","        return embeddings\n","\n","\n","class GloveEmbeddings(WordsEmbeddings):\n","    WORD_TO_VEC_MODEL_TXT_PATH = 'glove.twitter.27B.50d.txt'\n","    PKL_PATH = 'gloveembedding.pkl'\n","    N_FEATURES = 50\n","    WORD_MAX_SIZE = 60\n","\n","class FasttextEmbeddings(WordsEmbeddings):\n","    WORD_TO_VEC_MODEL_TXT_PATH = 'cc.en.300.vec'\n","    PKL_PATH = 'fasttext.pkl'\n","    N_FEATURES = 300\n","    WORD_MAX_SIZE = 60"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[],"source":["model_embeddings = FasttextEmbeddings()"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["preparing embedding matrix...\n","number of null word embeddings: 1\n"]}],"source":["# Crear la Embedding matrix de las secuencias\n","# en inglés\n","\n","print('preparing embedding matrix...')\n","embed_dim = model_embeddings.N_FEATURES\n","words_not_found = []\n","\n","# word_index provieen del tokenizer\n","\n","nb_words = min(MAX_VOCAB_SIZE, len(word2idx_inputs)-1) # vocab_size\n","embedding_matrix = np.zeros((nb_words, embed_dim))\n","for word, i in word2idx_inputs.items():\n","    if i >= nb_words:\n","        continue\n","    embedding_vector = model_embeddings.get_words_embeddings(word)[0]\n","    if (embedding_vector is not None) and len(embedding_vector) > 0:\n","        \n","        embedding_matrix[i] = embedding_vector\n","    else:\n","        # words not found in embedding index will be all-zeros.\n","        words_not_found.append(word)\n","\n","print('number of null word embeddings:', np.sum(np.sum(embedding_matrix**2, axis=1) == 0))"]},{"cell_type":"markdown","metadata":{"id":"3vKbhjtIwPgM"},"source":["### 4 - Entrenar el modelo\n","Entrenar un modelo basado en el esquema encoder-decoder utilizando los datos generados en los puntos anteriores. Utilce como referencias los ejemplos vistos en clase."]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model_6\"\n","__________________________________________________________________________________________________\n"," Layer (type)                Output Shape                 Param #   Connected to                  \n","==================================================================================================\n"," input_16 (InputLayer)       [(None, 9)]                  0         []                            \n","                                                                                                  \n"," input_17 (InputLayer)       [(None, 10)]                 0         []                            \n","                                                                                                  \n"," embedding_6 (Embedding)     (None, 9, 300)               539400    ['input_16[0][0]']            \n","                                                                                                  \n"," embedding_7 (Embedding)     (None, 10, 128)              231296    ['input_17[0][0]']            \n","                                                                                                  \n"," lstm_6 (LSTM)               [(None, 128),                219648    ['embedding_6[0][0]']         \n","                              (None, 128),                                                        \n","                              (None, 128)]                                                        \n","                                                                                                  \n"," lstm_7 (LSTM)               [(None, 10, 128),            131584    ['embedding_7[0][0]',         \n","                              (None, 128),                           'lstm_6[0][1]',              \n","                              (None, 128)]                           'lstm_6[0][2]']              \n","                                                                                                  \n"," dense_3 (Dense)             (None, 10, 1807)             233103    ['lstm_7[0][0]']              \n","                                                                                                  \n","==================================================================================================\n","Total params: 1355031 (5.17 MB)\n","Trainable params: 815631 (3.11 MB)\n","Non-trainable params: 539400 (2.06 MB)\n","__________________________________________________________________________________________________\n"]}],"source":["from keras.models import Model\n","from keras.layers import Input, LSTM, Dense\n","from keras.layers import Dropout\n","\n","n_units = 128\n","dropout_rate = 0.2  # Set your desired dropout rate\n","\n","# Define training encoder\n","encoder_inputs = Input(shape=(max_input_len))\n","encoder_embedding_layer = Embedding(\n","    input_dim=nb_words,\n","    output_dim=embed_dim,\n","    input_length=max_input_len,\n","    weights=[embedding_matrix],\n","    trainable=False)\n","encoder_inputs_x = encoder_embedding_layer(encoder_inputs)\n","\n","encoder = LSTM(n_units, return_state=True, dropout=dropout_rate, recurrent_dropout=dropout_rate)\n","encoder_outputs, state_h, state_c = encoder(encoder_inputs_x)\n","encoder_states = [state_h, state_c]\n","\n","# Define training decoder\n","decoder_inputs = Input(shape=(max_out_len))\n","decoder_embedding_layer = Embedding(\n","    input_dim=num_words_output,\n","    output_dim=n_units,\n","    input_length=max_out_len)\n","decoder_inputs_x = decoder_embedding_layer(decoder_inputs)\n","\n","decoder_lstm = LSTM(n_units, return_sequences=True, return_state=True, dropout=dropout_rate, recurrent_dropout=dropout_rate)\n","decoder_outputs, _, _ = decoder_lstm(decoder_inputs_x, initial_state=encoder_states)\n","\n","# Dense\n","decoder_dense = Dense(num_words_output, activation='softmax')\n","decoder_outputs = decoder_dense(decoder_outputs)\n","\n","model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n","\n","model.compile(loss='categorical_crossentropy', optimizer=\"Adam\", metrics=['accuracy'])\n","model.summary()\n"]},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[],"source":["# Modelo solo decoder (para realizar inferencia)\n","\n","# define inference decoder\n","decoder_state_input_h = Input(shape=(n_units,))\n","decoder_state_input_c = Input(shape=(n_units,))\n","decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n","\n","# En cada predicción habrá una sola palabra de entrada al decoder,\n","# que es la realimentación de la palabra anterior\n","# por lo que hay que modificar el input shape de la layer de Embedding\n","decoder_inputs_single = Input(shape=(1,))\n","decoder_inputs_single_x = decoder_embedding_layer(decoder_inputs_single)\n","\n","decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs_single_x, initial_state=decoder_states_inputs)\n","decoder_states = [state_h, state_c]\n","decoder_outputs = decoder_dense(decoder_outputs)\n","decoder_model = Model([decoder_inputs_single] + decoder_states_inputs, [decoder_outputs] + decoder_states)"]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/40\n","151/151 [==============================] - ETA: 0s - loss: 3.0791 - accuracy: 0.5186"]},{"ename":"InvalidArgumentError","evalue":"Graph execution error:\n\nDetected at node model_6/embedding_6/embedding_lookup defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/Users/carlosmontiel/anaconda3/envs/nlp/lib/python3.11/site-packages/ipykernel_launcher.py\", line 17, in <module>\n\n  File \"/Users/carlosmontiel/anaconda3/envs/nlp/lib/python3.11/site-packages/traitlets/config/application.py\", line 1053, in launch_instance\n\n  File \"/Users/carlosmontiel/anaconda3/envs/nlp/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 737, in start\n\n  File \"/Users/carlosmontiel/anaconda3/envs/nlp/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/Users/carlosmontiel/anaconda3/envs/nlp/lib/python3.11/asyncio/base_events.py\", line 607, in run_forever\n\n  File \"/Users/carlosmontiel/anaconda3/envs/nlp/lib/python3.11/asyncio/base_events.py\", line 1922, in _run_once\n\n  File \"/Users/carlosmontiel/anaconda3/envs/nlp/lib/python3.11/asyncio/events.py\", line 80, in _run\n\n  File \"/Users/carlosmontiel/anaconda3/envs/nlp/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 524, in dispatch_queue\n\n  File \"/Users/carlosmontiel/anaconda3/envs/nlp/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 513, in process_one\n\n  File \"/Users/carlosmontiel/anaconda3/envs/nlp/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 418, in dispatch_shell\n\n  File \"/Users/carlosmontiel/anaconda3/envs/nlp/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 758, in execute_request\n\n  File \"/Users/carlosmontiel/anaconda3/envs/nlp/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 426, in do_execute\n\n  File \"/Users/carlosmontiel/anaconda3/envs/nlp/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/Users/carlosmontiel/anaconda3/envs/nlp/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3046, in run_cell\n\n  File \"/Users/carlosmontiel/anaconda3/envs/nlp/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3101, in _run_cell\n\n  File \"/Users/carlosmontiel/anaconda3/envs/nlp/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"/Users/carlosmontiel/anaconda3/envs/nlp/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3306, in run_cell_async\n\n  File \"/Users/carlosmontiel/anaconda3/envs/nlp/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3488, in run_ast_nodes\n\n  File \"/Users/carlosmontiel/anaconda3/envs/nlp/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3548, in run_code\n\n  File \"/var/folders/k9/vb534jt106d2plphjzl86xcw0000gn/T/ipykernel_1335/20237295.py\", line 1, in <module>\n\n  File \"/Users/carlosmontiel/anaconda3/envs/nlp/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/Users/carlosmontiel/anaconda3/envs/nlp/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1832, in fit\n\n  File \"/Users/carlosmontiel/anaconda3/envs/nlp/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/Users/carlosmontiel/anaconda3/envs/nlp/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2272, in evaluate\n\n  File \"/Users/carlosmontiel/anaconda3/envs/nlp/lib/python3.11/site-packages/keras/src/engine/training.py\", line 4079, in run_step\n\n  File \"/Users/carlosmontiel/anaconda3/envs/nlp/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2042, in test_function\n\n  File \"/Users/carlosmontiel/anaconda3/envs/nlp/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2025, in step_function\n\n  File \"/Users/carlosmontiel/anaconda3/envs/nlp/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2013, in run_step\n\n  File \"/Users/carlosmontiel/anaconda3/envs/nlp/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1893, in test_step\n\n  File \"/Users/carlosmontiel/anaconda3/envs/nlp/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/Users/carlosmontiel/anaconda3/envs/nlp/lib/python3.11/site-packages/keras/src/engine/training.py\", line 589, in __call__\n\n  File \"/Users/carlosmontiel/anaconda3/envs/nlp/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/Users/carlosmontiel/anaconda3/envs/nlp/lib/python3.11/site-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/Users/carlosmontiel/anaconda3/envs/nlp/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/Users/carlosmontiel/anaconda3/envs/nlp/lib/python3.11/site-packages/keras/src/engine/functional.py\", line 515, in call\n\n  File \"/Users/carlosmontiel/anaconda3/envs/nlp/lib/python3.11/site-packages/keras/src/engine/functional.py\", line 672, in _run_internal_graph\n\n  File \"/Users/carlosmontiel/anaconda3/envs/nlp/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/Users/carlosmontiel/anaconda3/envs/nlp/lib/python3.11/site-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/Users/carlosmontiel/anaconda3/envs/nlp/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/Users/carlosmontiel/anaconda3/envs/nlp/lib/python3.11/site-packages/keras/src/layers/core/embedding.py\", line 272, in call\n\nindices[22,8] = 1798 is not in [0, 1798)\n\t [[{{node model_6/embedding_6/embedding_lookup}}]] [Op:__inference_test_function_25576]","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[1;32m/Users/carlosmontiel/Documents/UBA/4to Bimestre/NLP/Clase 6/6- bot_qa.ipynb Cell 24\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/carlosmontiel/Documents/UBA/4to%20Bimestre/NLP/Clase%206/6-%20bot_qa.ipynb#X33sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m hist \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/carlosmontiel/Documents/UBA/4to%20Bimestre/NLP/Clase%206/6-%20bot_qa.ipynb#X33sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     [encoder_input_sequences, decoder_input_sequences],\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/carlosmontiel/Documents/UBA/4to%20Bimestre/NLP/Clase%206/6-%20bot_qa.ipynb#X33sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     decoder_targets,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/carlosmontiel/Documents/UBA/4to%20Bimestre/NLP/Clase%206/6-%20bot_qa.ipynb#X33sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m40\u001b[39;49m, \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/carlosmontiel/Documents/UBA/4to%20Bimestre/NLP/Clase%206/6-%20bot_qa.ipynb#X33sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     validation_split\u001b[39m=\u001b[39;49m\u001b[39m0.2\u001b[39;49m)\n","File \u001b[0;32m~/anaconda3/envs/nlp/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n","File \u001b[0;32m~/anaconda3/envs/nlp/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m   \u001b[39m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[1;32m     54\u001b[0m   inputs \u001b[39m=\u001b[39m [\n\u001b[1;32m     55\u001b[0m       tensor_conversion_registry\u001b[39m.\u001b[39mconvert(t)\n\u001b[1;32m     56\u001b[0m       \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(t, core_types\u001b[39m.\u001b[39mTensor)\n\u001b[1;32m     57\u001b[0m       \u001b[39melse\u001b[39;00m t\n\u001b[1;32m     58\u001b[0m       \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m inputs\n\u001b[1;32m     59\u001b[0m   ]\n\u001b[0;32m---> 60\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     61\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     62\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     63\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n","\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node model_6/embedding_6/embedding_lookup defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/Users/carlosmontiel/anaconda3/envs/nlp/lib/python3.11/site-packages/ipykernel_launcher.py\", line 17, in <module>\n\n  File \"/Users/carlosmontiel/anaconda3/envs/nlp/lib/python3.11/site-packages/traitlets/config/application.py\", line 1053, in launch_instance\n\n  File \"/Users/carlosmontiel/anaconda3/envs/nlp/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 737, in start\n\n  File \"/Users/carlosmontiel/anaconda3/envs/nlp/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/Users/carlosmontiel/anaconda3/envs/nlp/lib/python3.11/asyncio/base_events.py\", line 607, in run_forever\n\n  File \"/Users/carlosmontiel/anaconda3/envs/nlp/lib/python3.11/asyncio/base_events.py\", line 1922, in _run_once\n\n  File \"/Users/carlosmontiel/anaconda3/envs/nlp/lib/python3.11/asyncio/events.py\", line 80, in _run\n\n  File \"/Users/carlosmontiel/anaconda3/envs/nlp/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 524, in dispatch_queue\n\n  File \"/Users/carlosmontiel/anaconda3/envs/nlp/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 513, in process_one\n\n  File \"/Users/carlosmontiel/anaconda3/envs/nlp/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 418, in dispatch_shell\n\n  File \"/Users/carlosmontiel/anaconda3/envs/nlp/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 758, in execute_request\n\n  File \"/Users/carlosmontiel/anaconda3/envs/nlp/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 426, in do_execute\n\n  File \"/Users/carlosmontiel/anaconda3/envs/nlp/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/Users/carlosmontiel/anaconda3/envs/nlp/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3046, in run_cell\n\n  File \"/Users/carlosmontiel/anaconda3/envs/nlp/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3101, in _run_cell\n\n  File \"/Users/carlosmontiel/anaconda3/envs/nlp/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"/Users/carlosmontiel/anaconda3/envs/nlp/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3306, in run_cell_async\n\n  File \"/Users/carlosmontiel/anaconda3/envs/nlp/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3488, in run_ast_nodes\n\n  File \"/Users/carlosmontiel/anaconda3/envs/nlp/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3548, in run_code\n\n  File \"/var/folders/k9/vb534jt106d2plphjzl86xcw0000gn/T/ipykernel_1335/20237295.py\", line 1, in <module>\n\n  File \"/Users/carlosmontiel/anaconda3/envs/nlp/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/Users/carlosmontiel/anaconda3/envs/nlp/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1832, in fit\n\n  File \"/Users/carlosmontiel/anaconda3/envs/nlp/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/Users/carlosmontiel/anaconda3/envs/nlp/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2272, in evaluate\n\n  File \"/Users/carlosmontiel/anaconda3/envs/nlp/lib/python3.11/site-packages/keras/src/engine/training.py\", line 4079, in run_step\n\n  File \"/Users/carlosmontiel/anaconda3/envs/nlp/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2042, in test_function\n\n  File \"/Users/carlosmontiel/anaconda3/envs/nlp/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2025, in step_function\n\n  File \"/Users/carlosmontiel/anaconda3/envs/nlp/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2013, in run_step\n\n  File \"/Users/carlosmontiel/anaconda3/envs/nlp/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1893, in test_step\n\n  File \"/Users/carlosmontiel/anaconda3/envs/nlp/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/Users/carlosmontiel/anaconda3/envs/nlp/lib/python3.11/site-packages/keras/src/engine/training.py\", line 589, in __call__\n\n  File \"/Users/carlosmontiel/anaconda3/envs/nlp/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/Users/carlosmontiel/anaconda3/envs/nlp/lib/python3.11/site-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/Users/carlosmontiel/anaconda3/envs/nlp/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/Users/carlosmontiel/anaconda3/envs/nlp/lib/python3.11/site-packages/keras/src/engine/functional.py\", line 515, in call\n\n  File \"/Users/carlosmontiel/anaconda3/envs/nlp/lib/python3.11/site-packages/keras/src/engine/functional.py\", line 672, in _run_internal_graph\n\n  File \"/Users/carlosmontiel/anaconda3/envs/nlp/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/Users/carlosmontiel/anaconda3/envs/nlp/lib/python3.11/site-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/Users/carlosmontiel/anaconda3/envs/nlp/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/Users/carlosmontiel/anaconda3/envs/nlp/lib/python3.11/site-packages/keras/src/layers/core/embedding.py\", line 272, in call\n\nindices[22,8] = 1798 is not in [0, 1798)\n\t [[{{node model_6/embedding_6/embedding_lookup}}]] [Op:__inference_test_function_25576]"]}],"source":["hist = model.fit(\n","    [encoder_input_sequences, decoder_input_sequences],\n","    decoder_targets,\n","    epochs=40, \n","    validation_split=0.2)"]},{"cell_type":"markdown","metadata":{"id":"Zbwn0ekDy_s2"},"source":["### 5 - Inferencia\n","Experimentar el funcionamiento de su modelo. Recuerde que debe realizar la inferencia de los modelos por separado de encoder y decoder."]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"provenance":[]},"kernelspec":{"display_name":"Python 3.10.6 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"},"vscode":{"interpreter":{"hash":"916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"}}},"nbformat":4,"nbformat_minor":0}
